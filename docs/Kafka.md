# Kafka란?
- Apache Kafka는 고성능 데이터 파이프라인, 스트리밍 분석, 데이터 통합 및 미션 크리티컬 애플리케이션을 위해<br>
오픈 소스 **분산 이벤트 스트리밍 플랫폼(distributed event streaming platform)**이다.

## Kafka와 같은 이벤트 브로커를 사용하는 이유
### 서버 컴포넌트간의 직접의존을 방지하기 위해서 사용한다.
<img src="https://github.com/hyewon218/kim-jpa2/assets/126750615/70c1b781-83a4-44a7-9d09-7ce9e65aa238" width="60%"/><br>

#### 위 아키텍처의 문제점
- 서버 컴포넌트가 서로 직접 의존되어 있는 경우 상대방 시스템의 변경에 따라 의존하는 시스템도 변경해주어야 한다.
- 의존되는 시스템에 장애가 발생할 경우 의존하는 시스템도 영향을 받아서 장애가 발생할 수 있다.<br>

<img src="https://github.com/hyewon218/kim-jpa2/assets/126750615/47f499c0-228a-4bcd-8fec-a9a7acbefb08" width="60%"/><br>
- 다음과 같이 Kafka를 메세지 브로커로서 두면 시스템간에 직접 메시지를 주고 받지 않기 때문에 위의 두 문제를 해결할 수 있다.
- 이벤트 발행자는 **kafka에게 어떻게 메시지를 발행할지**만 고민하면 되고 이벤트 수신자는 **Kafka에서 메시지를 수신하여 어떻게 처리할지**만 고민하면 된다.

### 동기 방식을 비동기 방식으로 전환함과 동시에 관심사를 분리하기 위해서 사용한다.
- 예를 들어 내가 쓴 글에 타인이 좋아요를 누를 경우 알림이 울리는 기능이 있다고 하자.
- 이 기능에는 크게 두가지의 관심사가 있는데
  - 첫번째 관심사는, **like를 저장**하는 관심사
  - 두번째 관심사는, **알림을 저장하고 발송**하는 관심사
- 첫번째 관심사는 좋아요를 누르고 나서 사용자가 정상 응답을 받는 사이에 **동기적**으로 이루어지면서 좋아요가 저장되어야 한다. 
- 두번째 관심사는 좋아요를 저장하는 것과 꼭 함께 이루어져야할 필요는 없고 **비동기적으로 이루어져도 상관이 없다.**
- 이 두 관심사를 모두 동기적으로 처리하고 하나의 시스템에서 처리한다면 **알림 기능에서 장애가 발생했을 때 좋아요가 눌리는 기능 자체가 실패할 수 있다.**
- 이 때 `kafka`를 활용하면 좋아요를 눌렀을 때 **Kafka에 이벤트를 발행만 하는 것**으로 대체하고 **비동기적으로 Consumer 그룹에서 이벤트를 읽고 처리할 수 있다.**
- 따라서, **알림 기능에 장애가 발생하더라도 좋아요 기능은 제대로 수행 될 수 있다.**

### 단일 진실 공급원으로서 활용한다.
- 서버 아키텍처에서 데이터는 cache, RDB, 여러 NOSQL 등에 분산되어 저장될 수 있는데 이때 각 DataSource에서 데이터의 내용은 다를 수 있다.
- Kafka에 event를 발행하고 그 event를 각각의 DataSource가 서로 다른 Consumer Group으로서 저장 및 처리하는 방식으로 구성하면 각각의 DataSource의 현재 데이터 형상이 다를 때 실제 데이터는 Kafka에 발행한 Event라고 정의할 수 있다.

<br>

## Kafka 핵심 개념들
<img src="https://github.com/hyewon218/kim-jpa2/assets/126750615/8a6c0e8a-a4e5-4b97-aeb5-9c4cfcacdd9f" width="60%"/><br>
### Message Broker와 Event Broker인 Kafka의 차이점
- Message Broker에는 RabbitMQ, ActiveMQ, RedisQueue등이 있다.
- 가장 큰 차이는 Event Broker Kafka의 경우 publish 한 event를 반영구적으로 **저장**할 수 있다는 점이다. Message Broker에서는 subscribe한 메시지를 저장하기 힘들다.
  - kafka의 경우 이벤트를 저장하기 때문에 이벤트 발행 및 소비여부를 보장할 수 있으며, **장애가 발생 했을 때 재처리**할 수 있다.
  - 단일 진실 공급원으로서 활용할 수 있다.
- 따라서 이벤트 브로커는 메시지 브로커로도 활용될 수 있지만 메시지 브로커를 이벤트 브로커로 활용할 수는 없다.

### Topic
- topic은 이벤트를 발행하거나 혹은 발행한 이벤트를 소비하는 곳을 지정하는 개념이다.
- 따라서 이벤트 발행 및 소비 시 토픽을 지정해주어야 한다.
- 토픽내 에는 여러개의 Partition이 존재하여 이벤트는 각각의 Partition에 분리되어 저장된다.




# 알림 기능 구조 변경
## 수정 내용
   - 알림을 생성하는 것과 sse알림을 보내는 것을 같은 이벤트에 대해서 다르게 처리하는 Consumer group 두 개로 분리 및 Kafka Consumer Config변경
   - 트랜잭션 외부에서 이벤트 발행

### 기능 개선 후 동작 flow
1. Client에서 **Sse연결을 요청**하면 Server에서는 **연결 객체를 생성**하여 이를 **서버 인메모리 내에 저장**하고 **Client에게 연결 정보를 제공**해줍니다.<br>
2. 댓글 작성, 글 참여 등의 **이벤트(특정 사용자가 API호출 시)가 발생**하면 해당 요청내용을 먼저 처리한 후 정상 처리 된다면 **알림 이벤트를 produce**하여 **kafka에 발행**합니다.
3. kafka에 저장된 알림 이벤트는 두 Consumer Group에 의해서 consume 되며<br>
**첫 번째 Consumer Group** 은 **알림 이벤트 데이터로 알림 엔티티를 만들어서 RDB에 저장**하고 **두 번째 Consumer Group**은 **SSE 응답을 보내기 위해 Redis pub/sub에 pub 메시지를 보냅니다**.
4. Redis channel에 pub 메시지가 보내지면 해당 채널을 구독하고 있는 subscriber 들에게 메시지가 push 됩니다. **subscriber** 들은 `Web Application Server`들 입니다.
5. `Web Application Server`가 redis pub 메시지를 수신하면 다음 로직을 수행합니다. <br>
   - 먼저 인메모리 내의 **ConcurrentHashMap** 에서 pub 메시지 정보에 해당하는 내용으로 **SseEmitter 객체**를 찾을 수 있는지 확인합니다.<br>
     - 이는 해당 WAS가 **SSE 응답을 보내야 하는 클라이언트와 연결된 WAS인지 확인**하는 과정이기도 합니다. <br>
   - **SseEmitter를 하나라도 찾은 WAS**는 **SSE 응답을 클라이언트에게 보내고** 이 응답을 통해 클라이언트는 스스로 요청(polling)하지 않고 **알림 내역을 비동기적으로 응답 받을 수 있습니다**.